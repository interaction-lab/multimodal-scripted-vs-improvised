{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/interactionlab/anaconda3/envs/vlm-llm-2025/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # for NVIDIA GPUs\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "eda_df = pd.read_csv(\"eda_iemocap_no_utts_dataset.csv\")\n",
    "eda_df = eda_df[[\"speaker\", \"utt_id\", \"EDA\"]]\n",
    "filename_ids = []\n",
    "speaker_M_F = []\n",
    "session_numbers = []\n",
    "for i, row in eda_df.iterrows():\n",
    "    match = re.search(r\"b'(Ses(\\d+)[MF]_.+\\d+.*)_([MF])\", row[\"speaker\"])\n",
    "    filename_ids.append(match.group(1))\n",
    "    session_numbers.append(int(match.group(2))) \n",
    "    speaker_M_F.append(match.group(3))\n",
    "eda_df = eda_df.drop(columns=[\"speaker\"])\n",
    "eda_df[\"filename\"] = filename_ids\n",
    "eda_df[\"filename\"] = eda_df[\"filename\"].astype(str)\n",
    "eda_df[\"session_number\"] = session_numbers\n",
    "eda_df[\"session_number\"] = eda_df[\"session_number\"].astype(int)\n",
    "eda_df[\"speaker\"] = speaker_M_F\n",
    "eda_df[\"speaker\"] = eda_df[\"speaker\"].astype(str)\n",
    "eda_df[\"utt_id\"] = eda_df[\"utt_id\"].astype(int)\n",
    "# Access transcipt files based on filename\n",
    "utt_df = []\n",
    "root_dir = \"IEMOCAP_full_release/\"\n",
    "for i in range(1, 6):\n",
    "    directory = os.path.join(root_dir, f\"Session{i}/dialog/transcriptions/\")\n",
    "    for entry in os.scandir(directory):  \n",
    "        if entry.is_file() and entry.path.endswith(\".txt\"):  # check if it's a file\n",
    "            try:\n",
    "                with open(entry.path, \"r\") as file:\n",
    "                    filename = entry.path.split(\"/\")[-1][:-4]\n",
    "                    lines = file.readlines()\n",
    "                    for order, line in enumerate(lines):\n",
    "                        speaker_info, utterance = line.split(\":\")[0], line.split(\":\")[1]\n",
    "                        pattern = r\"(F|M)(\\d+)\\s\\[(\\d+\\.\\d+)-(\\d+\\.\\d+)\\]\"\n",
    "                        match = re.search(pattern, speaker_info)\n",
    "                        if match is None:\n",
    "                            continue\n",
    "                        speaker_f_m = match.group(1)\n",
    "                        utt_id = match.group(2)\n",
    "                        start = match.group(3)\n",
    "                        end = match.group(4)\n",
    "                        utt_df.append({\"utt_id\": int(utt_id), \"filename\": str(filename), \"start\": float(start), \"end\": float(end), \"speaker\": str(speaker_f_m.strip()), \"utterance\": utterance.strip(), \"session_number\": int(i), \"original_order\": order})\n",
    "            except:\n",
    "                #print(entry.path) # these are meta files with ._ prepended to text file name\n",
    "                continue\n",
    "utt_df = pd.DataFrame(utt_df)\n",
    "# Combine the EDA and utterances together\n",
    "final_df = pd.merge(eda_df, utt_df, on=[\"utt_id\", \"session_number\", \"filename\", \"speaker\"])\n",
    "final_df\n",
    "\n",
    "def scripted_splits():    \n",
    "    # session 1\n",
    "    df_scripted_session_1_script_1_M = final_df[(final_df[\"filename\"].str.contains(\"M_script01\")) & (final_df[\"session_number\"] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_1_script_1_F = final_df[(final_df[\"filename\"].str.contains(\"F_script01\")) & (final_df[\"session_number\"] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_1_script_2_M = final_df[(final_df[\"filename\"].str.contains(\"M_script02\")) & (final_df[\"session_number\"] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_1_script_2_F = final_df[(final_df[\"filename\"].str.contains(\"F_script02\")) & (final_df[\"session_number\"] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_1_script_3_M = final_df[(final_df[\"filename\"].str.contains(\"M_script03\")) & (final_df[\"session_number\"] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_1_script_3_F = final_df[(final_df[\"filename\"].str.contains(\"F_script03\")) & (final_df[\"session_number\"] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "\n",
    "    # session 2\n",
    "    df_scripted_session_2_script_1_M = final_df[(final_df[\"filename\"].str.contains(\"M_script01\")) & (final_df[\"session_number\"] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_2_script_1_F = final_df[(final_df[\"filename\"].str.contains(\"F_script01\")) & (final_df[\"session_number\"] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_2_script_2_M = final_df[(final_df[\"filename\"].str.contains(\"M_script02\")) & (final_df[\"session_number\"] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_2_script_2_F = final_df[(final_df[\"filename\"].str.contains(\"F_script02\")) & (final_df[\"session_number\"] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_2_script_3_M = final_df[(final_df[\"filename\"].str.contains(\"M_script03\")) & (final_df[\"session_number\"] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_2_script_3_F = final_df[(final_df[\"filename\"].str.contains(\"F_script03\")) & (final_df[\"session_number\"] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "\n",
    "    # session 3\n",
    "    df_scripted_session_3_script_1_M = final_df[(final_df[\"filename\"].str.contains(\"M_script01\")) & (final_df[\"session_number\"] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_3_script_1_F = final_df[(final_df[\"filename\"].str.contains(\"F_script01\")) & (final_df[\"session_number\"] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_3_script_2_M = final_df[(final_df[\"filename\"].str.contains(\"M_script02\")) & (final_df[\"session_number\"] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_3_script_2_F = final_df[(final_df[\"filename\"].str.contains(\"F_script02\")) & (final_df[\"session_number\"] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_3_script_3_M = final_df[(final_df[\"filename\"].str.contains(\"M_script03\")) & (final_df[\"session_number\"] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_3_script_3_F = final_df[(final_df[\"filename\"].str.contains(\"F_script03\")) & (final_df[\"session_number\"] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "\n",
    "    # session 4\n",
    "    df_scripted_session_4_script_1_M = final_df[(final_df[\"filename\"].str.contains(\"M_script01\")) & (final_df[\"session_number\"] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_4_script_1_F = final_df[(final_df[\"filename\"].str.contains(\"F_script01\")) & (final_df[\"session_number\"] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_4_script_2_M = final_df[(final_df[\"filename\"].str.contains(\"M_script02\")) & (final_df[\"session_number\"] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_4_script_2_F = final_df[(final_df[\"filename\"].str.contains(\"F_script02\")) & (final_df[\"session_number\"] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_4_script_3_M = final_df[(final_df[\"filename\"].str.contains(\"M_script03\")) & (final_df[\"session_number\"] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_4_script_3_F = final_df[(final_df[\"filename\"].str.contains(\"F_script03\")) & (final_df[\"session_number\"] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "\n",
    "    # session 5\n",
    "    df_scripted_session_5_script_1_M = final_df[(final_df[\"filename\"].str.contains(\"M_script01\")) & (final_df[\"session_number\"] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_5_script_1_F = final_df[(final_df[\"filename\"].str.contains(\"F_script01\")) & (final_df[\"session_number\"] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_5_script_2_M = final_df[(final_df[\"filename\"].str.contains(\"M_script02\")) & (final_df[\"session_number\"] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_5_script_2_F = final_df[(final_df[\"filename\"].str.contains(\"F_script02\")) & (final_df[\"session_number\"] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_5_script_3_M = final_df[(final_df[\"filename\"].str.contains(\"M_script03\")) & (final_df[\"session_number\"] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_scripted_session_5_script_3_F = final_df[(final_df[\"filename\"].str.contains(\"F_script03\")) & (final_df[\"session_number\"] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "\n",
    "    # need to this for each script across sections because although they are the same script, the lines are not memorized perfectly and so there are some length differences\n",
    "    min_script_1 = min([len(df_scripted_session_1_script_1_F), len(df_scripted_session_1_script_1_M),\\\n",
    "                        len(df_scripted_session_2_script_1_F), len(df_scripted_session_2_script_1_M),\\\n",
    "                        len(df_scripted_session_3_script_1_F), len(df_scripted_session_3_script_1_M),\\\n",
    "                        len(df_scripted_session_4_script_1_F), len(df_scripted_session_4_script_1_M),\\\n",
    "                        len(df_scripted_session_5_script_1_F), len(df_scripted_session_5_script_1_M)])\n",
    "\n",
    "    min_script_2 = min([len(df_scripted_session_1_script_2_F), len(df_scripted_session_1_script_2_M),\\\n",
    "                        len(df_scripted_session_2_script_2_F), len(df_scripted_session_2_script_2_M),\\\n",
    "                        len(df_scripted_session_3_script_2_F), len(df_scripted_session_3_script_2_M),\\\n",
    "                        len(df_scripted_session_4_script_2_F), len(df_scripted_session_4_script_2_M),\\\n",
    "                        len(df_scripted_session_5_script_2_F), len(df_scripted_session_5_script_2_M)])\n",
    "\n",
    "    min_script_3 = min([len(df_scripted_session_1_script_3_F), len(df_scripted_session_1_script_3_M),\\\n",
    "                        len(df_scripted_session_2_script_3_F), len(df_scripted_session_2_script_3_M),\\\n",
    "                        len(df_scripted_session_3_script_3_F), len(df_scripted_session_3_script_3_M),\\\n",
    "                        len(df_scripted_session_4_script_3_F), len(df_scripted_session_4_script_3_M),\\\n",
    "                        len(df_scripted_session_5_script_3_F), len(df_scripted_session_5_script_3_M)])\n",
    "\n",
    "    train_script_1 = int(min_script_1*0.8)\n",
    "    val_script_1 = (min_script_1-train_script_1)//2\n",
    "\n",
    "    train_script_2 = int(min_script_2*0.8)\n",
    "    val_script_2 = (min_script_2-train_script_2)//2\n",
    "\n",
    "    train_script_3 = int(min_script_3*0.8)\n",
    "    val_script_3 = (min_script_3-train_script_3)//2\n",
    "\n",
    "    #df_scripted_session_1_script_1_F.sample(frac=1) # going to ignore this for now and not shuffle within each script because that means merging sessions... to confusing and not perfect matching\n",
    "    df_scripted_train = pd.concat([df_scripted_session_1_script_1_F[:train_script_1],\n",
    "                                df_scripted_session_1_script_1_M[:train_script_1],\n",
    "                                df_scripted_session_2_script_1_F[:train_script_1], \n",
    "                                df_scripted_session_2_script_1_M[:train_script_1], \n",
    "                                df_scripted_session_3_script_1_F[:train_script_1],\n",
    "                                df_scripted_session_3_script_1_M[:train_script_1],\n",
    "                                df_scripted_session_4_script_1_F[:train_script_1],\n",
    "                                df_scripted_session_4_script_1_M[:train_script_1],\n",
    "                                df_scripted_session_5_script_1_F[:train_script_1],\n",
    "                                df_scripted_session_5_script_1_M[:train_script_1],\n",
    "                                df_scripted_session_1_script_2_F[:train_script_2],\n",
    "                                df_scripted_session_1_script_2_M[:train_script_2],\n",
    "                                df_scripted_session_2_script_2_F[:train_script_2], \n",
    "                                df_scripted_session_2_script_2_M[:train_script_2], \n",
    "                                df_scripted_session_3_script_2_F[:train_script_2],\n",
    "                                df_scripted_session_3_script_2_M[:train_script_2],\n",
    "                                df_scripted_session_4_script_2_F[:train_script_2],\n",
    "                                df_scripted_session_4_script_2_M[:train_script_2],\n",
    "                                df_scripted_session_5_script_2_F[:train_script_2],\n",
    "                                df_scripted_session_5_script_2_M[:train_script_2],\n",
    "                                df_scripted_session_1_script_3_F[:train_script_3],\n",
    "                                df_scripted_session_1_script_3_M[:train_script_3],\n",
    "                                df_scripted_session_2_script_3_F[:train_script_3], \n",
    "                                df_scripted_session_2_script_3_M[:train_script_3], \n",
    "                                df_scripted_session_3_script_3_F[:train_script_3],\n",
    "                                df_scripted_session_3_script_3_M[:train_script_3],\n",
    "                                df_scripted_session_4_script_3_F[:train_script_3],\n",
    "                                df_scripted_session_4_script_3_M[:train_script_3],\n",
    "                                df_scripted_session_5_script_3_F[:train_script_3],\n",
    "                                df_scripted_session_5_script_3_M[:train_script_3]])\n",
    "\n",
    "    df_scripted_val = pd.concat([df_scripted_session_1_script_1_F[train_script_1: train_script_1+val_script_1],\n",
    "                                df_scripted_session_1_script_1_M[train_script_1: train_script_1+val_script_1],\n",
    "                                df_scripted_session_2_script_1_F[train_script_1: train_script_1+val_script_1], \n",
    "                                df_scripted_session_2_script_1_M[train_script_1: train_script_1+val_script_1], \n",
    "                                df_scripted_session_3_script_1_F[train_script_1: train_script_1+val_script_1],\n",
    "                                df_scripted_session_3_script_1_M[train_script_1: train_script_1+val_script_1],\n",
    "                                df_scripted_session_4_script_1_F[train_script_1: train_script_1+val_script_1],\n",
    "                                df_scripted_session_4_script_1_M[train_script_1: train_script_1+val_script_1],\n",
    "                                df_scripted_session_5_script_1_F[train_script_1: train_script_1+val_script_1],\n",
    "                                df_scripted_session_5_script_1_M[train_script_1: train_script_1+val_script_1],\n",
    "                                df_scripted_session_1_script_2_F[train_script_2: train_script_2+val_script_2],\n",
    "                                df_scripted_session_1_script_2_M[train_script_2: train_script_2+val_script_2],\n",
    "                                df_scripted_session_2_script_2_F[train_script_2: train_script_2+val_script_2], \n",
    "                                df_scripted_session_2_script_2_M[train_script_2: train_script_2+val_script_2], \n",
    "                                df_scripted_session_3_script_2_F[train_script_2: train_script_2+val_script_2],\n",
    "                                df_scripted_session_3_script_2_M[train_script_2: train_script_2+val_script_2],\n",
    "                                df_scripted_session_4_script_2_F[train_script_2: train_script_2+val_script_2],\n",
    "                                df_scripted_session_4_script_2_M[train_script_2: train_script_2+val_script_2],\n",
    "                                df_scripted_session_5_script_2_F[train_script_2: train_script_2+val_script_2],\n",
    "                                df_scripted_session_5_script_2_M[train_script_2: train_script_2+val_script_2],\n",
    "                                df_scripted_session_1_script_3_F[train_script_3: train_script_3+val_script_3],\n",
    "                                df_scripted_session_1_script_3_M[train_script_3: train_script_3+val_script_3],\n",
    "                                df_scripted_session_2_script_3_F[train_script_3: train_script_3+val_script_3], \n",
    "                                df_scripted_session_2_script_3_M[train_script_3: train_script_3+val_script_3], \n",
    "                                df_scripted_session_3_script_3_F[train_script_3: train_script_3+val_script_3],\n",
    "                                df_scripted_session_3_script_3_M[train_script_3: train_script_3+val_script_3],\n",
    "                                df_scripted_session_4_script_3_F[train_script_3: train_script_3+val_script_3],\n",
    "                                df_scripted_session_4_script_3_M[train_script_3: train_script_3+val_script_3],\n",
    "                                df_scripted_session_5_script_3_F[train_script_3: train_script_3+val_script_3],\n",
    "                                df_scripted_session_5_script_3_M[train_script_3: train_script_3+val_script_3]])\n",
    "\n",
    "    df_scripted_test = pd.concat([df_scripted_session_1_script_1_F[train_script_1+val_script_1:],\n",
    "                                df_scripted_session_1_script_1_M[train_script_1+val_script_1:],\n",
    "                                df_scripted_session_2_script_1_F[train_script_1+val_script_1:], \n",
    "                                df_scripted_session_2_script_1_M[train_script_1+val_script_1:], \n",
    "                                df_scripted_session_3_script_1_F[train_script_1+val_script_1:],\n",
    "                                df_scripted_session_3_script_1_M[train_script_1+val_script_1:],\n",
    "                                df_scripted_session_4_script_1_F[train_script_1+val_script_1:],\n",
    "                                df_scripted_session_5_script_1_F[train_script_1+val_script_1:],\n",
    "                                df_scripted_session_5_script_1_M[train_script_1+val_script_1:],\n",
    "                                df_scripted_session_1_script_2_F[train_script_2+val_script_2:],\n",
    "                                df_scripted_session_1_script_2_M[train_script_2+val_script_2:],\n",
    "                                df_scripted_session_2_script_2_F[train_script_2+val_script_2:], \n",
    "                                df_scripted_session_2_script_2_M[train_script_2+val_script_2:], \n",
    "                                df_scripted_session_3_script_2_F[train_script_2+val_script_2:],\n",
    "                                df_scripted_session_3_script_2_M[train_script_2+val_script_2:],\n",
    "                                df_scripted_session_4_script_2_F[train_script_2+val_script_2:],\n",
    "                                df_scripted_session_4_script_2_M[train_script_2+val_script_2:],\n",
    "                                df_scripted_session_5_script_2_F[train_script_2+val_script_2:],\n",
    "                                df_scripted_session_5_script_2_M[train_script_2+val_script_2:],\n",
    "                                df_scripted_session_1_script_3_F[train_script_3+val_script_3:],\n",
    "                                df_scripted_session_1_script_3_M[train_script_3+val_script_3:],\n",
    "                                df_scripted_session_2_script_3_F[train_script_3+val_script_3:], \n",
    "                                df_scripted_session_2_script_3_M[train_script_3+val_script_3:], \n",
    "                                df_scripted_session_3_script_3_F[train_script_3+val_script_3:],\n",
    "                                df_scripted_session_3_script_3_M[train_script_3+val_script_3:],\n",
    "                                df_scripted_session_4_script_3_F[train_script_3+val_script_3:],\n",
    "                                df_scripted_session_4_script_3_M[train_script_3+val_script_3:],\n",
    "                                df_scripted_session_5_script_3_F[train_script_3+val_script_3:],\n",
    "                                df_scripted_session_5_script_3_M[train_script_3+val_script_3:]])\n",
    "\n",
    "    # need to split separately across the different sessions since they all have the same scripts\n",
    "    # df_session_1_script_1 = pd.merge(df_scripted_session_1_script_1_F, df_scripted_session_1_script_1_M, on=[\"utt_id\", \"session_number\", \"improv_script_id\", \"speaker\"])\n",
    "    # df_session_2_script_1 = pd.merge(df_scripted_session_2_script_1_F, df_scripted_session_2_script_1_M, on=[\"utt_id\", \"session_number\", \"improv_script_id\", \"speaker\"])\n",
    "    # df_session_3_script_1 = pd.merge(df_scripted_session_3_script_1_F, df_scripted_session_3_script_1_M, on=[\"utt_id\", \"session_number\", \"improv_script_id\", \"speaker\"])\n",
    "    # df_session_4_script_1 = pd.merge(df_scripted_session_4_script_1_F, df_scripted_session_4_script_1_M, on=[\"utt_id\", \"session_number\", \"improv_script_id\", \"speaker\"])\n",
    "    # df_session_5_script_1 = pd.merge(df_scripted_session_5_script_1_F, df_scripted_session_5_script_1_M, on=[\"utt_id\", \"session_number\", \"improv_script_id\", \"speaker\"])\n",
    "\n",
    "    return df_scripted_train, df_scripted_val, df_scripted_test\n",
    "\n",
    "def impro_splits():    \n",
    "    # session 1\n",
    "    df_impro_session_1_impro_1_M = final_df[(final_df['filename'].str.contains('M_impro01')) & (final_df['session_number'] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_1_impro_1_F = final_df[(final_df['filename'].str.contains('F_impro01')) & (final_df['session_number'] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_1_impro_2_M = final_df[(final_df['filename'].str.contains('M_impro02')) & (final_df['session_number'] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_1_impro_2_F = final_df[(final_df['filename'].str.contains('F_impro02')) & (final_df['session_number'] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_1_impro_3_M = final_df[(final_df['filename'].str.contains('M_impro03')) & (final_df['session_number'] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_1_impro_3_F = final_df[(final_df['filename'].str.contains('F_impro03')) & (final_df['session_number'] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_1_impro_4_M = final_df[(final_df['filename'].str.contains('M_impro04')) & (final_df['session_number'] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_1_impro_4_F = final_df[(final_df['filename'].str.contains('F_impro04')) & (final_df['session_number'] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_1_impro_5_M = final_df[(final_df['filename'].str.contains('M_impro05')) & (final_df['session_number'] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_1_impro_5_F = final_df[(final_df['filename'].str.contains('F_impro05')) & (final_df['session_number'] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_1_impro_6_M = final_df[(final_df['filename'].str.contains('M_impro06')) & (final_df['session_number'] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_1_impro_6_F = final_df[(final_df['filename'].str.contains('F_impro06')) & (final_df['session_number'] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_1_impro_7_M = final_df[(final_df['filename'].str.contains('M_impro07')) & (final_df['session_number'] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_1_impro_7_F = final_df[(final_df['filename'].str.contains('F_impro07')) & (final_df['session_number'] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_1_impro_8_M = final_df[(final_df['filename'].str.contains('M_impro08')) & (final_df['session_number'] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_1_impro_8_F = final_df[(final_df['filename'].str.contains('F_impro08')) & (final_df['session_number'] == 1)].sort_values(by=['filename', 'original_order'])\n",
    "\n",
    "    # session 2\n",
    "    df_impro_session_2_impro_1_M = final_df[(final_df['filename'].str.contains('M_impro01')) & (final_df['session_number'] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_2_impro_1_F = final_df[(final_df['filename'].str.contains('F_impro01')) & (final_df['session_number'] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_2_impro_2_M = final_df[(final_df['filename'].str.contains('M_impro02')) & (final_df['session_number'] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_2_impro_2_F = final_df[(final_df['filename'].str.contains('F_impro02')) & (final_df['session_number'] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_2_impro_3_M = final_df[(final_df['filename'].str.contains('M_impro03')) & (final_df['session_number'] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_2_impro_3_F = final_df[(final_df['filename'].str.contains('F_impro03')) & (final_df['session_number'] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_2_impro_4_M = final_df[(final_df['filename'].str.contains('M_impro04')) & (final_df['session_number'] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_2_impro_4_F = final_df[(final_df['filename'].str.contains('F_impro04')) & (final_df['session_number'] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_2_impro_5_M = final_df[(final_df['filename'].str.contains('M_impro05')) & (final_df['session_number'] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_2_impro_5_F = final_df[(final_df['filename'].str.contains('F_impro05')) & (final_df['session_number'] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_2_impro_6_M = final_df[(final_df['filename'].str.contains('M_impro06')) & (final_df['session_number'] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_2_impro_6_F = final_df[(final_df['filename'].str.contains('F_impro06')) & (final_df['session_number'] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_2_impro_7_M = final_df[(final_df['filename'].str.contains('M_impro07')) & (final_df['session_number'] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_2_impro_7_F = final_df[(final_df['filename'].str.contains('F_impro07')) & (final_df['session_number'] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_2_impro_8_M = final_df[(final_df['filename'].str.contains('M_impro08')) & (final_df['session_number'] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_2_impro_8_F = final_df[(final_df['filename'].str.contains('F_impro08')) & (final_df['session_number'] == 2)].sort_values(by=['filename', 'original_order'])\n",
    "\n",
    "    # session 3\n",
    "    df_impro_session_3_impro_1_M = final_df[(final_df['filename'].str.contains('M_impro01')) & (final_df['session_number'] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_3_impro_1_F = final_df[(final_df['filename'].str.contains('F_impro01')) & (final_df['session_number'] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_3_impro_2_M = final_df[(final_df['filename'].str.contains('M_impro02')) & (final_df['session_number'] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_3_impro_2_F = final_df[(final_df['filename'].str.contains('F_impro02')) & (final_df['session_number'] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_3_impro_3_M = final_df[(final_df['filename'].str.contains('M_impro03')) & (final_df['session_number'] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_3_impro_3_F = final_df[(final_df['filename'].str.contains('F_impro03')) & (final_df['session_number'] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_3_impro_4_M = final_df[(final_df['filename'].str.contains('M_impro04')) & (final_df['session_number'] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_3_impro_4_F = final_df[(final_df['filename'].str.contains('F_impro04')) & (final_df['session_number'] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_3_impro_5_M = final_df[(final_df['filename'].str.contains('M_impro05')) & (final_df['session_number'] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_3_impro_5_F = final_df[(final_df['filename'].str.contains('F_impro05')) & (final_df['session_number'] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_3_impro_6_M = final_df[(final_df['filename'].str.contains('M_impro06')) & (final_df['session_number'] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_3_impro_6_F = final_df[(final_df['filename'].str.contains('F_impro06')) & (final_df['session_number'] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_3_impro_7_M = final_df[(final_df['filename'].str.contains('M_impro07')) & (final_df['session_number'] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_3_impro_7_F = final_df[(final_df['filename'].str.contains('F_impro07')) & (final_df['session_number'] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_3_impro_8_M = final_df[(final_df['filename'].str.contains('M_impro08')) & (final_df['session_number'] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_3_impro_8_F = final_df[(final_df['filename'].str.contains('F_impro08')) & (final_df['session_number'] == 3)].sort_values(by=['filename', 'original_order'])\n",
    "\n",
    "    # session 4\n",
    "    df_impro_session_4_impro_1_M = final_df[(final_df['filename'].str.contains('M_impro01')) & (final_df['session_number'] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_4_impro_1_F = final_df[(final_df['filename'].str.contains('F_impro01')) & (final_df['session_number'] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_4_impro_2_M = final_df[(final_df['filename'].str.contains('M_impro02')) & (final_df['session_number'] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_4_impro_2_F = final_df[(final_df['filename'].str.contains('F_impro02')) & (final_df['session_number'] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_4_impro_3_M = final_df[(final_df['filename'].str.contains('M_impro03')) & (final_df['session_number'] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_4_impro_3_F = final_df[(final_df['filename'].str.contains('F_impro03')) & (final_df['session_number'] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_4_impro_4_M = final_df[(final_df['filename'].str.contains('M_impro04')) & (final_df['session_number'] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_4_impro_4_F = final_df[(final_df['filename'].str.contains('F_impro04')) & (final_df['session_number'] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_4_impro_5_M = final_df[(final_df['filename'].str.contains('M_impro05')) & (final_df['session_number'] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_4_impro_5_F = final_df[(final_df['filename'].str.contains('F_impro05')) & (final_df['session_number'] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_4_impro_6_M = final_df[(final_df['filename'].str.contains('M_impro06')) & (final_df['session_number'] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_4_impro_6_F = final_df[(final_df['filename'].str.contains('F_impro06')) & (final_df['session_number'] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_4_impro_7_M = final_df[(final_df['filename'].str.contains('M_impro07')) & (final_df['session_number'] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_4_impro_7_F = final_df[(final_df['filename'].str.contains('F_impro07')) & (final_df['session_number'] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_4_impro_8_M = final_df[(final_df['filename'].str.contains('M_impro08')) & (final_df['session_number'] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_4_impro_8_F = final_df[(final_df['filename'].str.contains('F_impro08')) & (final_df['session_number'] == 4)].sort_values(by=['filename', 'original_order'])\n",
    "\n",
    "    # session 5\n",
    "    df_impro_session_5_impro_1_M = final_df[(final_df['filename'].str.contains('M_impro01')) & (final_df['session_number'] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_5_impro_1_F = final_df[(final_df['filename'].str.contains('F_impro01')) & (final_df['session_number'] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_5_impro_2_M = final_df[(final_df['filename'].str.contains('M_impro02')) & (final_df['session_number'] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_5_impro_2_F = final_df[(final_df['filename'].str.contains('F_impro02')) & (final_df['session_number'] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_5_impro_3_M = final_df[(final_df['filename'].str.contains('M_impro03')) & (final_df['session_number'] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_5_impro_3_F = final_df[(final_df['filename'].str.contains('F_impro03')) & (final_df['session_number'] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_5_impro_4_M = final_df[(final_df['filename'].str.contains('M_impro04')) & (final_df['session_number'] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_5_impro_4_F = final_df[(final_df['filename'].str.contains('F_impro04')) & (final_df['session_number'] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_5_impro_5_M = final_df[(final_df['filename'].str.contains('M_impro05')) & (final_df['session_number'] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_5_impro_5_F = final_df[(final_df['filename'].str.contains('F_impro05')) & (final_df['session_number'] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_5_impro_6_M = final_df[(final_df['filename'].str.contains('M_impro06')) & (final_df['session_number'] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_5_impro_6_F = final_df[(final_df['filename'].str.contains('F_impro06')) & (final_df['session_number'] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_5_impro_7_M = final_df[(final_df['filename'].str.contains('M_impro07')) & (final_df['session_number'] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_5_impro_7_F = final_df[(final_df['filename'].str.contains('F_impro07')) & (final_df['session_number'] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_5_impro_8_M = final_df[(final_df['filename'].str.contains('M_impro08')) & (final_df['session_number'] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "    df_impro_session_5_impro_8_F = final_df[(final_df['filename'].str.contains('F_impro08')) & (final_df['session_number'] == 5)].sort_values(by=['filename', 'original_order'])\n",
    "\n",
    "    # need to this for each impro across sections because although they are the same impro, the lines are not memorized perfectly and so there are some length differences\n",
    "    min_impro_1 = min([len(df_impro_session_1_impro_1_F), len(df_impro_session_1_impro_1_M),\\\n",
    "                        len(df_impro_session_2_impro_1_F), len(df_impro_session_2_impro_1_M),\\\n",
    "                        len(df_impro_session_3_impro_1_F), len(df_impro_session_3_impro_1_M),\\\n",
    "                        len(df_impro_session_4_impro_1_F), len(df_impro_session_4_impro_1_M),\\\n",
    "                        len(df_impro_session_5_impro_1_F), len(df_impro_session_5_impro_1_M)])\n",
    "\n",
    "    min_impro_2 = min([len(df_impro_session_1_impro_2_F), len(df_impro_session_1_impro_2_M),\\\n",
    "                        len(df_impro_session_2_impro_2_F), len(df_impro_session_2_impro_2_M),\\\n",
    "                        len(df_impro_session_3_impro_2_F), len(df_impro_session_3_impro_2_M),\\\n",
    "                        len(df_impro_session_4_impro_2_F), len(df_impro_session_4_impro_2_M),\\\n",
    "                        len(df_impro_session_5_impro_2_F), len(df_impro_session_5_impro_2_M)])\n",
    "\n",
    "    min_impro_3 = min([len(df_impro_session_1_impro_3_F), len(df_impro_session_1_impro_3_M),\\\n",
    "                        len(df_impro_session_2_impro_3_F), len(df_impro_session_2_impro_3_M),\\\n",
    "                        len(df_impro_session_3_impro_3_F), len(df_impro_session_3_impro_3_M),\\\n",
    "                        len(df_impro_session_4_impro_3_F), len(df_impro_session_4_impro_3_M),\\\n",
    "                        len(df_impro_session_5_impro_3_F), len(df_impro_session_5_impro_3_M)])\n",
    "\n",
    "    min_impro_4 = min([len(df_impro_session_1_impro_4_F), len(df_impro_session_1_impro_4_M),\\\n",
    "                        len(df_impro_session_2_impro_4_F), len(df_impro_session_2_impro_4_M),\\\n",
    "                        len(df_impro_session_3_impro_4_F), len(df_impro_session_3_impro_4_M),\\\n",
    "                        len(df_impro_session_4_impro_4_F), len(df_impro_session_4_impro_4_M),\\\n",
    "                        len(df_impro_session_5_impro_4_F), len(df_impro_session_5_impro_4_M)])\n",
    "\n",
    "    min_impro_5 = min([len(df_impro_session_1_impro_5_F), len(df_impro_session_1_impro_5_M),\\\n",
    "                            len(df_impro_session_2_impro_5_F), len(df_impro_session_2_impro_5_M),\\\n",
    "                            len(df_impro_session_3_impro_5_F), len(df_impro_session_3_impro_5_M),\\\n",
    "                            len(df_impro_session_4_impro_5_F), len(df_impro_session_4_impro_5_M),\\\n",
    "                            len(df_impro_session_5_impro_5_F), len(df_impro_session_5_impro_5_M)])\n",
    "\n",
    "    min_impro_6 = min([len(df_impro_session_1_impro_6_F), len(df_impro_session_1_impro_6_M),\\\n",
    "                            len(df_impro_session_2_impro_6_F), len(df_impro_session_2_impro_6_M),\\\n",
    "                            len(df_impro_session_3_impro_6_F), len(df_impro_session_3_impro_6_M),\\\n",
    "                            len(df_impro_session_4_impro_6_F), len(df_impro_session_4_impro_6_M),\\\n",
    "                            len(df_impro_session_5_impro_6_F), len(df_impro_session_5_impro_6_M)])\n",
    "\n",
    "    min_impro_7 = min([len(df_impro_session_1_impro_7_F), len(df_impro_session_1_impro_7_M),\\\n",
    "                            len(df_impro_session_2_impro_7_F), len(df_impro_session_2_impro_7_M),\\\n",
    "                            len(df_impro_session_3_impro_7_F), len(df_impro_session_3_impro_7_M),\\\n",
    "                            len(df_impro_session_4_impro_7_F), len(df_impro_session_4_impro_7_M),\\\n",
    "                            len(df_impro_session_5_impro_7_F), len(df_impro_session_5_impro_7_M)])\n",
    "\n",
    "    min_impro_8 = min([len(df_impro_session_2_impro_8_F), len(df_impro_session_2_impro_8_M),\\\n",
    "                            len(df_impro_session_3_impro_8_F), len(df_impro_session_3_impro_8_M),\\\n",
    "                            len(df_impro_session_4_impro_8_F), len(df_impro_session_4_impro_8_M),\\\n",
    "                            len(df_impro_session_5_impro_8_F), len(df_impro_session_5_impro_8_M)])\n",
    "\n",
    "    train_impro_1 = int(min_impro_1*0.8)\n",
    "    val_impro_1 = (min_impro_1-train_impro_1)//2\n",
    "\n",
    "    train_impro_2 = int(min_impro_2*0.8)\n",
    "    val_impro_2 = (min_impro_2-train_impro_2)//2\n",
    "\n",
    "    train_impro_3 = int(min_impro_3*0.8)\n",
    "    val_impro_3 = (min_impro_3-train_impro_3)//2\n",
    "\n",
    "    train_impro_4 = int(min_impro_4*0.8)\n",
    "    val_impro_4 = (min_impro_4-train_impro_4)//2\n",
    "\n",
    "    train_impro_5 = int(min_impro_5*0.8)\n",
    "    val_impro_5 = (min_impro_5-train_impro_5)//2\n",
    "\n",
    "    train_impro_6 = int(min_impro_6*0.8)\n",
    "    val_impro_6 = (min_impro_6-train_impro_6)//2\n",
    "\n",
    "    train_impro_7 = int(min_impro_7*0.8)\n",
    "    val_impro_7 = (min_impro_7-train_impro_7)//2\n",
    "\n",
    "    train_impro_8 = int(min_impro_8*0.8)\n",
    "    val_impro_8 = (min_impro_8-train_impro_8)//2\n",
    "\n",
    "\n",
    "    #df_impro_session_1_impro_1_F.sample(frac=1) # going to ignore this for now and not shuffle within each impro because that means merging sessions... to confusing and not perfect matching\n",
    "    df_impro_train = pd.concat([df_impro_session_1_impro_1_F[:train_impro_1],\n",
    "                                df_impro_session_1_impro_1_M[:train_impro_1],\n",
    "                                df_impro_session_2_impro_1_F[:train_impro_1], \n",
    "                                df_impro_session_2_impro_1_M[:train_impro_1], \n",
    "                                df_impro_session_3_impro_1_F[:train_impro_1],\n",
    "                                df_impro_session_3_impro_1_M[:train_impro_1],\n",
    "                                df_impro_session_4_impro_1_F[:train_impro_1],\n",
    "                                df_impro_session_4_impro_1_M[:train_impro_1],\n",
    "                                df_impro_session_5_impro_1_F[:train_impro_1],\n",
    "                                df_impro_session_5_impro_1_M[:train_impro_1],\n",
    "                                df_impro_session_1_impro_2_F[:train_impro_2],\n",
    "                                df_impro_session_1_impro_2_M[:train_impro_2],\n",
    "                                df_impro_session_2_impro_2_F[:train_impro_2], \n",
    "                                df_impro_session_2_impro_2_M[:train_impro_2], \n",
    "                                df_impro_session_3_impro_2_F[:train_impro_2],\n",
    "                                df_impro_session_3_impro_2_M[:train_impro_2],\n",
    "                                df_impro_session_4_impro_2_F[:train_impro_2],\n",
    "                                df_impro_session_4_impro_2_M[:train_impro_2],\n",
    "                                df_impro_session_5_impro_2_F[:train_impro_2],\n",
    "                                df_impro_session_5_impro_2_M[:train_impro_2],\n",
    "                                df_impro_session_1_impro_3_F[:train_impro_3],\n",
    "                                df_impro_session_1_impro_3_M[:train_impro_3],\n",
    "                                df_impro_session_2_impro_3_F[:train_impro_3], \n",
    "                                df_impro_session_2_impro_3_M[:train_impro_3], \n",
    "                                df_impro_session_3_impro_3_F[:train_impro_3],\n",
    "                                df_impro_session_3_impro_3_M[:train_impro_3],\n",
    "                                df_impro_session_4_impro_3_F[:train_impro_3],\n",
    "                                df_impro_session_4_impro_3_M[:train_impro_3],\n",
    "                                df_impro_session_5_impro_3_F[:train_impro_3],\n",
    "                                df_impro_session_5_impro_3_M[:train_impro_3],\n",
    "                                df_impro_session_1_impro_4_F[:train_impro_4],\n",
    "                                df_impro_session_1_impro_4_M[:train_impro_4],\n",
    "                                df_impro_session_2_impro_4_F[:train_impro_4], \n",
    "                                df_impro_session_2_impro_4_M[:train_impro_4], \n",
    "                                df_impro_session_3_impro_4_F[:train_impro_4],\n",
    "                                df_impro_session_3_impro_4_M[:train_impro_4],\n",
    "                                df_impro_session_4_impro_4_F[:train_impro_4],\n",
    "                                df_impro_session_4_impro_4_M[:train_impro_4],\n",
    "                                df_impro_session_5_impro_4_F[:train_impro_4],\n",
    "                                df_impro_session_5_impro_4_M[:train_impro_4],\n",
    "                                df_impro_session_1_impro_5_F[:train_impro_5],\n",
    "                                df_impro_session_1_impro_5_M[:train_impro_5],\n",
    "                                df_impro_session_2_impro_5_F[:train_impro_5], \n",
    "                                df_impro_session_2_impro_5_M[:train_impro_5], \n",
    "                                df_impro_session_3_impro_5_F[:train_impro_5],\n",
    "                                df_impro_session_3_impro_5_M[:train_impro_5],\n",
    "                                df_impro_session_4_impro_5_F[:train_impro_5],\n",
    "                                df_impro_session_4_impro_5_M[:train_impro_5],\n",
    "                                df_impro_session_5_impro_5_F[:train_impro_5],\n",
    "                                df_impro_session_5_impro_5_M[:train_impro_5],\n",
    "                                df_impro_session_1_impro_6_F[:train_impro_6],\n",
    "                                df_impro_session_1_impro_6_M[:train_impro_6],\n",
    "                                df_impro_session_2_impro_6_F[:train_impro_6], \n",
    "                                df_impro_session_2_impro_6_M[:train_impro_6], \n",
    "                                df_impro_session_3_impro_6_F[:train_impro_6],\n",
    "                                df_impro_session_3_impro_6_M[:train_impro_6],\n",
    "                                df_impro_session_4_impro_6_F[:train_impro_6],\n",
    "                                df_impro_session_4_impro_6_M[:train_impro_6],\n",
    "                                df_impro_session_5_impro_6_F[:train_impro_6],\n",
    "                                df_impro_session_5_impro_6_M[:train_impro_6],\n",
    "                                df_impro_session_1_impro_7_F[:train_impro_7],\n",
    "                                df_impro_session_1_impro_7_M[:train_impro_7],\n",
    "                                df_impro_session_2_impro_7_F[:train_impro_7], \n",
    "                                df_impro_session_2_impro_7_M[:train_impro_7], \n",
    "                                df_impro_session_3_impro_7_F[:train_impro_7],\n",
    "                                df_impro_session_3_impro_7_M[:train_impro_7],\n",
    "                                df_impro_session_4_impro_7_F[:train_impro_7],\n",
    "                                df_impro_session_4_impro_7_M[:train_impro_7],\n",
    "                                df_impro_session_5_impro_7_F[:train_impro_7],\n",
    "                                df_impro_session_5_impro_7_M[:train_impro_7],\n",
    "                                df_impro_session_2_impro_8_F[:train_impro_8], \n",
    "                                df_impro_session_2_impro_8_M[:train_impro_8], \n",
    "                                df_impro_session_3_impro_8_F[:train_impro_8],\n",
    "                                df_impro_session_3_impro_8_M[:train_impro_8],\n",
    "                                df_impro_session_4_impro_8_F[:train_impro_8],\n",
    "                                df_impro_session_4_impro_8_M[:train_impro_8],\n",
    "                                df_impro_session_5_impro_8_F[:train_impro_8],\n",
    "                                df_impro_session_5_impro_8_M[:train_impro_8]])  \n",
    "    df_impro_val = pd.concat([df_impro_session_1_impro_1_F[train_impro_1: train_impro_1+val_impro_1],\n",
    "                                df_impro_session_1_impro_1_M[train_impro_1: train_impro_1+val_impro_1],\n",
    "                                df_impro_session_2_impro_1_F[train_impro_1: train_impro_1+val_impro_1], \n",
    "                                df_impro_session_2_impro_1_M[train_impro_1: train_impro_1+val_impro_1], \n",
    "                                df_impro_session_3_impro_1_F[train_impro_1: train_impro_1+val_impro_1],\n",
    "                                df_impro_session_3_impro_1_M[train_impro_1: train_impro_1+val_impro_1],\n",
    "                                df_impro_session_4_impro_1_F[train_impro_1: train_impro_1+val_impro_1],\n",
    "                                df_impro_session_4_impro_1_M[train_impro_1: train_impro_1+val_impro_1],\n",
    "                                df_impro_session_5_impro_1_F[train_impro_1: train_impro_1+val_impro_1],\n",
    "                                df_impro_session_5_impro_1_M[train_impro_1: train_impro_1+val_impro_1],\n",
    "                                df_impro_session_1_impro_2_F[train_impro_2: train_impro_2+val_impro_2],\n",
    "                                df_impro_session_1_impro_2_M[train_impro_2: train_impro_2+val_impro_2],\n",
    "                                df_impro_session_2_impro_2_F[train_impro_2: train_impro_2+val_impro_2], \n",
    "                                df_impro_session_2_impro_2_M[train_impro_2: train_impro_2+val_impro_2], \n",
    "                                df_impro_session_3_impro_2_F[train_impro_2: train_impro_2+val_impro_2],\n",
    "                                df_impro_session_3_impro_2_M[train_impro_2: train_impro_2+val_impro_2],\n",
    "                                df_impro_session_4_impro_2_F[train_impro_2: train_impro_2+val_impro_2],\n",
    "                                df_impro_session_4_impro_2_M[train_impro_2: train_impro_2+val_impro_2],\n",
    "                                df_impro_session_5_impro_2_F[train_impro_2: train_impro_2+val_impro_2],\n",
    "                                df_impro_session_5_impro_2_M[train_impro_2: train_impro_2+val_impro_2],\n",
    "                                df_impro_session_1_impro_3_F[train_impro_3: train_impro_3+val_impro_3],\n",
    "                                df_impro_session_1_impro_3_M[train_impro_3: train_impro_3+val_impro_3],\n",
    "                                df_impro_session_2_impro_3_F[train_impro_3: train_impro_3+val_impro_3], \n",
    "                                df_impro_session_2_impro_3_M[train_impro_3: train_impro_3+val_impro_3], \n",
    "                                df_impro_session_3_impro_3_F[train_impro_3: train_impro_3+val_impro_3],\n",
    "                                df_impro_session_3_impro_3_M[train_impro_3: train_impro_3+val_impro_3],\n",
    "                                df_impro_session_4_impro_3_F[train_impro_3: train_impro_3+val_impro_3],\n",
    "                                df_impro_session_4_impro_3_M[train_impro_3: train_impro_3+val_impro_3],\n",
    "                                df_impro_session_5_impro_3_F[train_impro_3: train_impro_3+val_impro_3],\n",
    "                                df_impro_session_5_impro_3_M[train_impro_3: train_impro_3+val_impro_3],\n",
    "                                df_impro_session_1_impro_4_F[train_impro_4: train_impro_4+val_impro_4],\n",
    "                                df_impro_session_1_impro_4_M[train_impro_4: train_impro_4+val_impro_4],\n",
    "                                df_impro_session_2_impro_4_F[train_impro_4: train_impro_4+val_impro_4], \n",
    "                                df_impro_session_2_impro_4_M[train_impro_4: train_impro_4+val_impro_4], \n",
    "                                df_impro_session_3_impro_4_F[train_impro_4: train_impro_4+val_impro_4],\n",
    "                                df_impro_session_3_impro_4_M[train_impro_4: train_impro_4+val_impro_4],\n",
    "                                df_impro_session_4_impro_4_F[train_impro_4: train_impro_4+val_impro_4],\n",
    "                                df_impro_session_4_impro_4_M[train_impro_4: train_impro_4+val_impro_4],\n",
    "                                df_impro_session_5_impro_4_F[train_impro_4: train_impro_4+val_impro_4],\n",
    "                                df_impro_session_5_impro_4_M[train_impro_4: train_impro_4+val_impro_4],\n",
    "                                df_impro_session_1_impro_5_F[train_impro_5: train_impro_5+val_impro_5],\n",
    "                                df_impro_session_1_impro_5_M[train_impro_5: train_impro_5+val_impro_5],\n",
    "                                df_impro_session_2_impro_5_F[train_impro_5: train_impro_5+val_impro_5], \n",
    "                                df_impro_session_2_impro_5_M[train_impro_5: train_impro_5+val_impro_5], \n",
    "                                df_impro_session_3_impro_5_F[train_impro_5: train_impro_5+val_impro_5],\n",
    "                                df_impro_session_3_impro_5_M[train_impro_5: train_impro_5+val_impro_5],\n",
    "                                df_impro_session_4_impro_5_F[train_impro_5: train_impro_5+val_impro_5],\n",
    "                                df_impro_session_4_impro_5_M[train_impro_5: train_impro_5+val_impro_5],\n",
    "                                df_impro_session_5_impro_5_F[train_impro_5: train_impro_5+val_impro_5],\n",
    "                                df_impro_session_5_impro_5_M[train_impro_5: train_impro_5+val_impro_5],\n",
    "                                df_impro_session_1_impro_6_F[train_impro_6: train_impro_6+val_impro_6],\n",
    "                                df_impro_session_1_impro_6_M[train_impro_6: train_impro_6+val_impro_6],\n",
    "                                df_impro_session_2_impro_6_F[train_impro_6: train_impro_6+val_impro_6], \n",
    "                                df_impro_session_2_impro_6_M[train_impro_6: train_impro_6+val_impro_6], \n",
    "                                df_impro_session_3_impro_6_F[train_impro_6: train_impro_6+val_impro_6],\n",
    "                                df_impro_session_3_impro_6_M[train_impro_6: train_impro_6+val_impro_6],\n",
    "                                df_impro_session_4_impro_6_F[train_impro_6: train_impro_6+val_impro_6],\n",
    "                                df_impro_session_4_impro_6_M[train_impro_6: train_impro_6+val_impro_6],\n",
    "                                df_impro_session_5_impro_6_F[train_impro_6: train_impro_6+val_impro_6],\n",
    "                                df_impro_session_5_impro_6_M[train_impro_6: train_impro_6+val_impro_6],\n",
    "                                df_impro_session_1_impro_7_F[train_impro_7: train_impro_7+val_impro_7],\n",
    "                                df_impro_session_1_impro_7_M[train_impro_7: train_impro_7+val_impro_7],\n",
    "                                df_impro_session_2_impro_7_F[train_impro_7: train_impro_7+val_impro_7], \n",
    "                                df_impro_session_2_impro_7_M[train_impro_7: train_impro_7+val_impro_7], \n",
    "                                df_impro_session_3_impro_7_F[train_impro_7: train_impro_7+val_impro_7],\n",
    "                                df_impro_session_3_impro_7_M[train_impro_7: train_impro_7+val_impro_7],\n",
    "                                df_impro_session_4_impro_7_F[train_impro_7: train_impro_7+val_impro_7],\n",
    "                                df_impro_session_4_impro_7_M[train_impro_7: train_impro_7+val_impro_7],\n",
    "                                df_impro_session_5_impro_7_F[train_impro_7: train_impro_7+val_impro_7],\n",
    "                                df_impro_session_5_impro_7_M[train_impro_7: train_impro_7+val_impro_7],\n",
    "                                df_impro_session_2_impro_8_F[train_impro_8: train_impro_8+val_impro_8], \n",
    "                                df_impro_session_2_impro_8_M[train_impro_8: train_impro_8+val_impro_8], \n",
    "                                df_impro_session_3_impro_8_F[train_impro_8: train_impro_8+val_impro_8],\n",
    "                                df_impro_session_3_impro_8_M[train_impro_8: train_impro_8+val_impro_8],\n",
    "                                df_impro_session_4_impro_8_F[train_impro_8: train_impro_8+val_impro_8],\n",
    "                                df_impro_session_4_impro_8_M[train_impro_8: train_impro_8+val_impro_8],\n",
    "                                df_impro_session_5_impro_8_F[train_impro_8: train_impro_8+val_impro_8],\n",
    "                                df_impro_session_5_impro_8_M[train_impro_8: train_impro_8+val_impro_8]]) \n",
    "    df_impro_test = pd.concat([df_impro_session_1_impro_1_F[train_impro_1+val_impro_1:],\n",
    "                                df_impro_session_1_impro_1_M[train_impro_1+val_impro_1:],\n",
    "                                df_impro_session_2_impro_1_F[train_impro_1+val_impro_1:], \n",
    "                                df_impro_session_2_impro_1_M[train_impro_1+val_impro_1:], \n",
    "                                df_impro_session_3_impro_1_F[train_impro_1+val_impro_1:],\n",
    "                                df_impro_session_3_impro_1_M[train_impro_1+val_impro_1:],\n",
    "                                df_impro_session_4_impro_1_F[train_impro_1+val_impro_1:],\n",
    "                                df_impro_session_5_impro_1_F[train_impro_1+val_impro_1:],\n",
    "                                df_impro_session_5_impro_1_M[train_impro_1+val_impro_1:],\n",
    "                                df_impro_session_1_impro_2_F[train_impro_2+val_impro_2:],\n",
    "                                df_impro_session_1_impro_2_M[train_impro_2+val_impro_2:],\n",
    "                                df_impro_session_2_impro_2_F[train_impro_2+val_impro_2:], \n",
    "                                df_impro_session_2_impro_2_M[train_impro_2+val_impro_2:], \n",
    "                                df_impro_session_3_impro_2_F[train_impro_2+val_impro_2:],\n",
    "                                df_impro_session_3_impro_2_M[train_impro_2+val_impro_2:],\n",
    "                                df_impro_session_4_impro_2_F[train_impro_2+val_impro_2:],\n",
    "                                df_impro_session_4_impro_2_M[train_impro_2+val_impro_2:],\n",
    "                                df_impro_session_5_impro_2_F[train_impro_2+val_impro_2:],\n",
    "                                df_impro_session_5_impro_2_M[train_impro_2+val_impro_2:],\n",
    "                                df_impro_session_1_impro_3_F[train_impro_3+val_impro_3:],\n",
    "                                df_impro_session_1_impro_3_M[train_impro_3+val_impro_3:],\n",
    "                                df_impro_session_2_impro_3_F[train_impro_3+val_impro_3:], \n",
    "                                df_impro_session_2_impro_3_M[train_impro_3+val_impro_3:], \n",
    "                                df_impro_session_3_impro_3_F[train_impro_3+val_impro_3:],\n",
    "                                df_impro_session_3_impro_3_M[train_impro_3+val_impro_3:],\n",
    "                                df_impro_session_4_impro_3_F[train_impro_3+val_impro_3:],\n",
    "                                df_impro_session_4_impro_3_M[train_impro_3+val_impro_3:],\n",
    "                                df_impro_session_5_impro_3_F[train_impro_3+val_impro_3:],\n",
    "                                df_impro_session_5_impro_3_M[train_impro_3+val_impro_3:],\n",
    "                                df_impro_session_1_impro_4_F[train_impro_4+val_impro_4:],\n",
    "                                df_impro_session_1_impro_4_M[train_impro_4+val_impro_4:],\n",
    "                                df_impro_session_2_impro_4_F[train_impro_4+val_impro_4:], \n",
    "                                df_impro_session_2_impro_4_M[train_impro_4+val_impro_4:], \n",
    "                                df_impro_session_3_impro_4_F[train_impro_4+val_impro_4:],\n",
    "                                df_impro_session_3_impro_4_M[train_impro_4+val_impro_4:],\n",
    "                                df_impro_session_4_impro_4_F[train_impro_4+val_impro_4:],\n",
    "                                df_impro_session_4_impro_4_M[train_impro_4+val_impro_4:],\n",
    "                                df_impro_session_5_impro_4_F[train_impro_4+val_impro_4:],\n",
    "                                df_impro_session_5_impro_4_M[train_impro_4+val_impro_4:],\n",
    "                                df_impro_session_1_impro_5_F[train_impro_5+val_impro_5:],\n",
    "                                df_impro_session_1_impro_5_M[train_impro_5+val_impro_5:],\n",
    "                                df_impro_session_2_impro_5_F[train_impro_5+val_impro_5:], \n",
    "                                df_impro_session_2_impro_5_M[train_impro_5+val_impro_5:], \n",
    "                                df_impro_session_3_impro_5_F[train_impro_5+val_impro_5:],\n",
    "                                df_impro_session_3_impro_5_M[train_impro_5+val_impro_5:],\n",
    "                                df_impro_session_4_impro_5_F[train_impro_5+val_impro_5:],\n",
    "                                df_impro_session_4_impro_5_M[train_impro_5+val_impro_5:],\n",
    "                                df_impro_session_5_impro_5_F[train_impro_5+val_impro_5:],\n",
    "                                df_impro_session_5_impro_5_M[train_impro_5+val_impro_5:],\n",
    "                                df_impro_session_1_impro_6_F[train_impro_6+val_impro_6:],\n",
    "                                df_impro_session_1_impro_6_M[train_impro_6+val_impro_6:],\n",
    "                                df_impro_session_2_impro_6_F[train_impro_6+val_impro_6:], \n",
    "                                df_impro_session_2_impro_6_M[train_impro_6+val_impro_6:], \n",
    "                                df_impro_session_3_impro_6_F[train_impro_6+val_impro_6:],\n",
    "                                df_impro_session_3_impro_6_M[train_impro_6+val_impro_6:],\n",
    "                                df_impro_session_4_impro_6_F[train_impro_6+val_impro_6:],\n",
    "                                df_impro_session_4_impro_6_M[train_impro_6+val_impro_6:],\n",
    "                                df_impro_session_5_impro_6_F[train_impro_6+val_impro_6:],\n",
    "                                df_impro_session_5_impro_6_M[train_impro_6+val_impro_6:],\n",
    "                                df_impro_session_1_impro_7_F[train_impro_7+val_impro_7:],\n",
    "                                df_impro_session_1_impro_7_M[train_impro_7+val_impro_7:],\n",
    "                                df_impro_session_2_impro_7_F[train_impro_7+val_impro_7:], \n",
    "                                df_impro_session_2_impro_7_M[train_impro_7+val_impro_7:], \n",
    "                                df_impro_session_3_impro_7_F[train_impro_7+val_impro_7:],\n",
    "                                df_impro_session_3_impro_7_M[train_impro_7+val_impro_7:],\n",
    "                                df_impro_session_4_impro_7_F[train_impro_7+val_impro_7:],\n",
    "                                df_impro_session_4_impro_7_M[train_impro_7+val_impro_7:],\n",
    "                                df_impro_session_5_impro_7_F[train_impro_7+val_impro_7:],\n",
    "                                df_impro_session_5_impro_7_M[train_impro_7+val_impro_7:],\n",
    "                                df_impro_session_2_impro_8_F[train_impro_8+val_impro_8:], \n",
    "                                df_impro_session_2_impro_8_M[train_impro_8+val_impro_8:], \n",
    "                                df_impro_session_3_impro_8_F[train_impro_8+val_impro_8:],\n",
    "                                df_impro_session_3_impro_8_M[train_impro_8+val_impro_8:],\n",
    "                                df_impro_session_4_impro_8_F[train_impro_8+val_impro_8:],\n",
    "                                df_impro_session_4_impro_8_M[train_impro_8+val_impro_8:],\n",
    "                                df_impro_session_5_impro_8_F[train_impro_8+val_impro_8:],\n",
    "                                df_impro_session_5_impro_8_M[train_impro_8+val_impro_8:]]) \n",
    "    return df_impro_train, df_impro_val, df_impro_test\n",
    "\n",
    "df_train_scripted, df_val_scripted, df_test_scripted = scripted_splits()\n",
    "df_train_improv, df_val_improv, df_test_improv = impro_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/interactionlab/anaconda3/envs/vlm-llm-2025/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/interactionlab/anaconda3/envs/vlm-llm-2025/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/interactionlab/anaconda3/envs/vlm-llm-2025/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/interactionlab/anaconda3/envs/vlm-llm-2025/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/interactionlab/anaconda3/envs/vlm-llm-2025/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/interactionlab/anaconda3/envs/vlm-llm-2025/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%</th>\n",
       "      <th>^2</th>\n",
       "      <th>^q</th>\n",
       "      <th>aa</th>\n",
       "      <th>ad</th>\n",
       "      <th>b</th>\n",
       "      <th>ba</th>\n",
       "      <th>bf</th>\n",
       "      <th>bh</th>\n",
       "      <th>bk</th>\n",
       "      <th>...</th>\n",
       "      <th>qw</th>\n",
       "      <th>qy</th>\n",
       "      <th>qy^d</th>\n",
       "      <th>sd</th>\n",
       "      <th>sv</th>\n",
       "      <th>x</th>\n",
       "      <th>xx</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007253</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.002201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007253</td>\n",
       "      <td>0.037623</td>\n",
       "      <td>0.007253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007253</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>0.003218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.007253</td>\n",
       "      <td>2344.000000</td>\n",
       "      <td>2344.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             %   ^2    ^q    aa    ad     b    ba   bf   bh        bk  ...  \\\n",
       "precision  0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  0.0  0.000865  ...   \n",
       "recall     0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  0.0  0.500000  ...   \n",
       "f1-score   0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  0.0  0.001727  ...   \n",
       "support    3.0  3.0  13.0  32.0  27.0  92.0  40.0  2.0  7.0  2.000000  ...   \n",
       "\n",
       "             qw          qy  qy^d      sd     sv    x     xx  accuracy  \\\n",
       "precision   0.0    0.025391   0.0     0.0    0.0  0.0    0.0  0.007253   \n",
       "recall      0.0    0.066327   0.0     0.0    0.0  0.0    0.0  0.007253   \n",
       "f1-score    0.0    0.036723   0.0     0.0    0.0  0.0    0.0  0.007253   \n",
       "support    88.0  196.000000   8.0  1073.0  493.0  2.0  125.0  0.007253   \n",
       "\n",
       "             macro avg  weighted avg  \n",
       "precision     0.002013      0.002201  \n",
       "recall        0.037623      0.007253  \n",
       "f1-score      0.003440      0.003218  \n",
       "support    2344.000000   2344.000000  \n",
       "\n",
       "[4 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(set(Counter(final_df[\"EDA\"]).keys())) # there are 34 labels\n",
    "labels_to_num_mapping = {}\n",
    "for i, label in enumerate(labels):\n",
    "    labels_to_num_mapping[label] = i\n",
    "\n",
    "labels_to_num_mapping\n",
    "num_to_label_mapping = {}\n",
    "for key, val in labels_to_num_mapping.items():\n",
    "    num_to_label_mapping[val] = key\n",
    "\n",
    "model_card = \"FacebookAI/roberta-large\"\n",
    "output_dir = \"results/roberta-large_improv\"\n",
    "checkpoint = \"checkpoint-335/\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(os.path.join(output_dir, checkpoint))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_card)\n",
    "\n",
    "def evaluate_texts(texts, labels):\n",
    "    inputs = tokenizer(texts, padding=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    predicted_class_id = torch.argmax(logits, axis=1)\n",
    "    predictions = list(predicted_class_id)#.squeeze())\n",
    "    predictions = [num_to_label_mapping[int(x)] for x in predictions]\n",
    "    return classification_report(y_true=labels, y_pred=predictions, output_dict=True), predictions\n",
    "\n",
    "texts, labels = [utt.lower() for utt in list(df_test_improv[\"utterance\"])], list(df_test_improv[\"EDA\"])\n",
    "classification_report_dict, preds = evaluate_texts(texts, labels)\n",
    "df = pd.DataFrame(classification_report_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/interactionlab/anaconda3/envs/vlm-llm-2025/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/interactionlab/anaconda3/envs/vlm-llm-2025/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/interactionlab/anaconda3/envs/vlm-llm-2025/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/interactionlab/anaconda3/envs/vlm-llm-2025/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/interactionlab/anaconda3/envs/vlm-llm-2025/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/interactionlab/anaconda3/envs/vlm-llm-2025/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%</th>\n",
       "      <th>^2</th>\n",
       "      <th>^q</th>\n",
       "      <th>aa</th>\n",
       "      <th>ad</th>\n",
       "      <th>b</th>\n",
       "      <th>ba</th>\n",
       "      <th>bf</th>\n",
       "      <th>bh</th>\n",
       "      <th>bk</th>\n",
       "      <th>...</th>\n",
       "      <th>qw</th>\n",
       "      <th>qy</th>\n",
       "      <th>qy^d</th>\n",
       "      <th>sd</th>\n",
       "      <th>sv</th>\n",
       "      <th>x</th>\n",
       "      <th>xx</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062992</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.010666</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.097925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014911</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.010666</td>\n",
       "      <td>0.029549</td>\n",
       "      <td>0.010666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024115</td>\n",
       "      <td>0.007984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.010666</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>0.015603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>196.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1073.000000</td>\n",
       "      <td>493.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>0.010666</td>\n",
       "      <td>2344.000000</td>\n",
       "      <td>2344.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  %   ^2    ^q    aa    ad     b         ba   bf   bh  \\\n",
       "precision  0.016393  0.0   0.0   0.0   0.0   0.0   0.038462  0.0  0.0   \n",
       "recall     0.333333  0.0   0.0   0.0   0.0   0.0   0.025000  0.0  0.0   \n",
       "f1-score   0.031250  0.0   0.0   0.0   0.0   0.0   0.030303  0.0  0.0   \n",
       "support    3.000000  3.0  13.0  32.0  27.0  92.0  40.000000  2.0  7.0   \n",
       "\n",
       "                 bk  ...         qw     qy  qy^d           sd          sv  \\\n",
       "precision  0.009709  ...   0.015625    0.0   0.0     0.062992    0.250000   \n",
       "recall     0.500000  ...   0.022727    0.0   0.0     0.014911    0.004057   \n",
       "f1-score   0.019048  ...   0.018519    0.0   0.0     0.024115    0.007984   \n",
       "support    2.000000  ...  88.000000  196.0   8.0  1073.000000  493.000000   \n",
       "\n",
       "             x          xx  accuracy    macro avg  weighted avg  \n",
       "precision  0.0    0.285714  0.010666     0.021900      0.097925  \n",
       "recall     0.0    0.016000  0.010666     0.029549      0.010666  \n",
       "f1-score   0.0    0.030303  0.010666     0.005210      0.015603  \n",
       "support    2.0  125.000000  0.010666  2344.000000   2344.000000  \n",
       "\n",
       "[4 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts, labels = [utt.lower() for utt in list(df_test_scripted[\"utterance\"])], list(df_test_scripted[\"EDA\"])\n",
    "classification_report_dict, preds = evaluate_texts(texts, labels)\n",
    "df = pd.DataFrame(classification_report_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm-llm-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
